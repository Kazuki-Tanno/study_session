[TOC]
# メタヒューリスティクス概説
- ここでは，評価関数 $f(x)$ を**最小化**するような解 $x$ を探索するという状況を扱う

## メタ戦略の一般的な枠組
- メタ戦略の一般的な枠組は次のようになる :
  - **I (初期解生成)** ：初期解 $x$ を生成する．
  - **II (局所探索)** : $x$ を一般化された局所探索法で改善する．ここで行う局所探索を行うには以下の要素を決定する必要がある．
    - **A** : 近傍 $N(x)$ の定義
    - **B** : 解の評価関数 $\tilde{f}$
    - **C** : 移動戦略 (近傍 $N(x)$ の中を，どのような順番で調べて．どの解に移動するか)
    - **D** : 終了条件
  - **III (反復)** : メタ戦略の終了条件が満たされれば，暫定解を出力して探索を終了する．さもなければIに戻る．

- この枠組に則りメタ戦略を立案する上で，次の2つの要素を考慮する必要がある
  - *多様化能力* : より多様な構造の (広い範囲の) 解を探索する能力
  - *集中化能力* : 狭い範囲を高精度に探索する能力．メタ戦略は「よい解同士は似通った構造を持っている」という考え方 (proximate optimality pronciple, POP) という考え方に基づいている．この観点からは，これまでに得られた優秀な解に似通った解を集中的に探索することが望ましい

- この2つの要素のバランスをいかにとっていくかが重要となる．

## 単純局所探索法 (simple local search)
- 単純局所探索法は，山登り法や反復改善法とも呼ばれる最も単純なヒューリスティクス手法
- MLS法やILS法，GLS法などの手法で繰り返し利用される (部品のようなもの)
- ある解 $x$ の近傍 $N(x)$ を調べ，近傍 $N(x)$ 内に改善解 $x'$ があれば，$x:=x'$ に更新していくという操作を，近傍内に改善解が存在しなくなるまで繰り返す手法である．
- 具体的なアルゴリズム
  - $x$ は初期解
  - **step 1** : $k := 1$, $x^{(1)}:=x$ とする．
  - **step 2** : $\{ s \in N(x^{(k)}) | f(s) < f(x^{(k)}) \} = \empty$ ならば，$x^{(k)}$ を出力して終了．そうでないならば，改善解 $x' \in \{ s \in N(x^{(k)}) | f(s) < f(x^{(k)}) \}$ を1つ選んで，$x^{(k+1)}:=x'$ としたのち，$k := k+1$ としてstep 2に戻る．
- step 2における，次の解の選び方には以下の2つの方法がある
  - *即時移動戦略* : 近傍内をランダムな順番で調べ，最初に見つかった改善解に移動する (first admissible move strategy, FA)
  - *最良移動戦略* : 近傍内をすべて調べて最良解に移動する (best admissible move strategy, BA)
- FAの方が性能が高くなる場合が多い
- 近傍の定義の方法によって，1つの局所解を求めるのに要する時間や，局所解の優秀さは大きく変化する

## 代表的なメタ戦略
- 代表的なメタ戦略には以下のような手法がある
  1. MLS法 (multi-start local search)
  2. GRASP法 (greedy randomized adaptive search procedure)
  3. ILS法 (iterated local search)
  4. GLS法 (genetic local search)
  5. アント法
  6. 適応的多スタート法
  7. 誘導局所探索法
  8. 評価関数摂動法
  9. 探索空間平滑化法
  10. シミュレーテッドアニーリング
  11. 閾値受理法
  12. 大洪水法
  13. タブー探索法
- 今回は，単純局所探索法が実装できていれば，追加でお手軽に実装できるMLS法，GRASP法，ILS法，GLS法，誘導局所探索法の5つを概説する
- それ以外の手法は気が向けば次回に

### MLS法 (multi-start local search)
- 別名：多スタート局所探索法
- ランダムに初期解を生成→単純局所探索 を繰り返す方法
- メタ戦略の中ではかなり古くから用いられており，実装もかなり簡単
- 具体的なアルゴリズム
  - **step 1** : ランダムに初期解 $x$ を生成する．
  - **step 2** : 解 $x$ から単純局所探索法を行い，局所最適解 $x'$ を得る．
  - **step 3** :  終了条件を満たしていれば，今まで得られた局所最適解 $x'$ の中でもっとも優れたものを近似解として出力して，探索を終了する．そうでなければ，step 1 に戻る．
- 終了条件には，「$N$ 個の局所最適解が得られれば終了」や「一定時間経過したら終了」などがよく用いられる
- 単純局所探索が実装できていれば，ほぼすべての組合せ最適化に適応できる

### GRASP法 (greedy randomized adaptive search procedure)
- ランダム化欲張り法で初期解を生成→単純局所探索 を繰り返す方法
- 具体的なアルゴリズム
  - **step 1** : ランダム化欲張り法で初期解 $x$ を生成する．
  - **step 2** : 解 $x$ から単純局所探索法を行い，局所最適解 $x'$ を得る．
  - **step 3** :  終了条件を満たしていれば，今まで得られた局所最適解 $x'$ の中でもっとも優れたものを近似解として出力して，探索を終了する．そうでなければ，step 1 に戻る．
- ランダム化欲張り法は，解を生成する際の各ステップ (解に要素を加える操作) において，評価値の高い要素を上から $l$ 個候補として保持し，それらの中からランダムに解に加える要素を選択する方法
- 欲張り法の実装が容易な問題に対しては，手軽に構築することが可能
- 欲張り法に要する時間が非常に長くなる問題については，それほど良い精度が出ない可能性大

### ILS法 (iterated local search)
- 過去の探索で得られたよい解にランダムな変形を加えたものを初期解として，単純局所探索を繰り返す方法
- こちらが与えるパラメータによって，多様化性能と集中化性能をある程度コントロールできる
- 比較的単純な割に，かなり良い精度が出る場合が多い
- 具体的なアルゴリズム
  - $x_\mathrm{seed} $ は，次の局所探索の初期解を生成するために利用される解
  - $N^{(l)}(x) $ は，解 $x$ の広さ $l$ の近傍．こちらが事前に定義しておく必要があり，基本的に $|N^{(1)}(x)| \le |N^{(2)}(x)|\le \dots $となるように設計する
  - $t$ は非負の実数値をとるパラメータ，$l_\max$ は自然数をとるパラメータ
  - **step 1** : 適当な解を初期解として単純局所探索を行い，局所最適解 $x$ を得る．$x_\mathrm{seed} := x, l:= 1$ とする．
  - **step 2** : $N^{(l)}(x_\mathrm{seed})$ よりランダムに1つ解を選び，$x'$ とする．
  - **step 3** : $x'$ を初期解として単純局所探索を行い，局所最適解 $x$ を得る．
  - **step 4** : $f(x) \le f(x_\mathrm{seed})$なら (a) を行う．$f(x) > \le f(x_\mathrm{seed})$なら，確率 $p = e ^ {-(f(x) - f(x_\mathrm{seed}))/t}$ で (a) を行い，確率 $1-p$ で (b) を行う．
    - **(a)** : $x_\mathrm{seed} := x, l:=1$ とする．($x_\mathrm{seed}$に似た解を探すのを諦めて，別の解の付近を探すようにする)
    - **(b)** : $l:=\min\{l+1, l_\max\}$ とする．(更に広い範囲で $x_\mathrm{seed}$ に似た解を探す)
  - **step 5** : 終了条件を満たせば，暫定解を出力して探索を終了する．そうでなければ，step 2に戻る．
- $t$ を大きくすると多様化性能は上がり，集中化性能は下がる
- $l_\max$ を大きくすると多様化性能は上がり，集中化性能は下がる
- $t = 0$ とした場合は，step 4で $p=0$ とする．
- $t$ の適正値は問題により大きく変わるため，きちんと調整しない場合は $t = 0$ としておくのが安全
- 広さ1の近傍 $N^{(1)}$ は，単純局所探索で用いる近傍とは別のものを用意しておくのが望ましい．同じものに定義してしまうと，$x_\mathrm{seed}$の更新が一切行われなくなる可能性が生じてしまうため．

### GLS法 (genetic local search)
- 別名 : 遺伝的局所探索法
- 遺伝的アルゴリズムと局所探索法を組み合わせたもの
- 具体的なアルゴリズム
  - **step 1 (初期設定)** : 初期解集合 $P$ を生成する．
  - **step 2 (進化)** : $Q:=\empty$ としたあと，以下の (a) → (b) → (c) を反復し，新たな解集合 $Q$ を生成する．
    - **(a) 交叉** : $P$ の中から2つまたはそれ以上の解を選び，それらを組み合わせることによって新たな解を作る．
    - **(b) 突然変異** : $P$ から選んだ解または (a) で作成された解にランダムな変形を加える．
    - **(c) 改善** : (a) あるいは (b) で得られた解を初期解として，単純局所探索を行い，得られた局所解を $Q$ に加える．
  - **step 3 (淘汰)** : 新しく生成された解と，もとからあった解を併せた $P \cup Q$ より，$|P|$ 個の解を残し，あらためて $P$ とする．
  - **step 4 (反復)** : 終了条件を満たせば暫定解を出力し，探索を終了する．そうでなければ，step 2に戻る．
- (c) を除くと，単純な遺伝的アルゴリズムとなる
- 単純な遺伝的アルゴリズムは，それほど良い精度が出ない (MLS法と同程度) が，GLS法はILS法やアニーリング法と同程度の精度となることが多い
- step 3において，どのような戦略を取るかによって集中化能力や多様化能力を制御することが可能
- 交叉や突然変異などは，問題によっては実装が難しい場合もある

### 誘導的局所探索法
- 単純局所探索で用いる評価関数を適応的に変形させることで，多様化性能を確保する手法
- 簡単に言えば，前回の探索で得られた局所最適解 $x$ の構成要素 (例えば，巡回セールス問題の枝など) の中でコストの大きいものにペナルティを付加するような評価関数 $\tilde{f}$ を作成する．この評価関数 $\tilde{f}$ を用いて，$x$ を初期解とした単純局所探索を行うと，新たな局所最適解を得る．
- 具体的なアルゴリズム
  - **step 1** : すべての構成要素のペナルティを0とする．初期解 $x$ を生成する．
  - **step 2** : $x$ を初期解として，ペナルティによって修正された評価関数 $\tilde{f}$ を用いた単純局所探索を行い，$\tilde{f}$ のもとでの局所最適解 $x'$ を得る．
  - **step 3** : $x'$ に基づいてペナルティの値を修正する．
  - **step 4** : 終了条件が満たされていれば暫定解を出力して探索を終了する．そうでなければ，$x := x'$ としてstep 2に戻る．
- この手法では，解の構成要素をどのように定義するか，step 2において評価関数をペナルティによってどのように変形するか，step 3においてペナルティをどのように更新するかを決めなくてはならない
- 巡回セールスマン問題における例
  - step 2の評価関数の変形は，$\tilde{f}(x) =f(x) + \alpha \sum_{\{i,j\} \in \mathrm{Tour}(x)} p_{ij} $ とする．$p_{ij}$ は枝 $\{ i,j \}$ のペナルティ，$\alpha$ は非負のパラメータ．
  - step 3では，$\mathrm{Tour}(x')$ の中で，$d_{ij}/(1+p_{ij})$ が最大となる枝 $\{i,j\}$ に対して，$p_{ij} := p_{ij} + 1$ とする．
    - 巡回路の中で，距離 $d_{ij}$ が大きく，ペナルティ $p_{ij}$ が小さい枝に対して，ペナルティを加算していく
  
## メタ戦略を利用する際の指針
- 手軽なツールとして，メタ戦略を利用する際の指針として，以下のものが掲げられている．
  1. まず，MLS法を試みる．その際，何を近傍として用いるかについて十分検討する．
  2. より高い精度が要求される場合には，ILS法を試みる．
  3. ILS法であまり精度が得られなかった場合には，GLS法かシミュレーテッドアニーリングを試みる．

## 参考文献
- 柳浦睦憲，茨木俊秀，「経営科学のニューフロンティア2 組合せ最適化 -メタ戦略を中心として -」，朝倉書店，2001年．

